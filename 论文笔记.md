# 论文内容

**创新是经济和社会发展的重要驱动力，许多关于创新的信息都嵌入在专利和专利申请的半结构化数据中。尽管专利数据所表达的影响和新颖性很难通过传统方式衡量，但机器学习（ML）为评估新颖性、总结贡献和嵌入语义提供了一套有前景的技术。**

在本论文中，我们介绍了 **Harvard USPTO Patent Dataset (HUPD)**，这是一个大规模、结构良好且多用途的英语专利申请语料库，涵盖了 2004 年至 2018 年间提交至 **美国专利商标局（USPTO）** 的专利申请。该数据集包含 **超过 450 万篇专利文档**，规模比现有可比语料库大两到三倍。

与 NLP 领域先前提出的专利数据集不同，HUPD 包含的是**发明人提交版本的专利申请**，而不是最终批准的专利版本，这使得我们能够**首次使用 NLP 方法研究申请时的可专利性**。此外，该数据集的另一个新颖之处在于它**结合了丰富的结构化元数据**，并提供了完整的专利申请文本。通过提供每个申请的**元数据**以及所有的文本字段，该数据集使研究人员能够**执行新的 NLP 任务**，并利用结构化变量的变化进行分析。

作为 NLP 研究中 HUPD 数据集可能推动的一项新任务，我们引入了**专利决策的二分类任务**。此外，我们展示了该数据集中提供的**结构化元数据**如何使我们能够对该任务的概念漂移（concept shifts）进行明确的研究。

最后，我们展示了该数据集还可以用于**其他 NLP 任务**，例如**专利主题的多类别分类、语言建模和文本摘要**。总的来说，**HUPD 是目前最大的多用途 NLP 数据集之一**，它不仅包含**领域特定的文本数据**，还包含**结构良好的书目信息元数据**，旨在推动研究，扩展语言和分类模型，使其能够适应多样化且动态变化的真实世界数据分布。



**专利是衡量创新和技术进步的重要公共指标。它们提供了一种简单而强大的信息来源，用于研究、衡量和评估创新活动、经济增长以及新兴技术。**

在过去二十年间，美国专利商标局（USPTO）每年收到的专利申请总数几乎翻了一番。仅在**2020 财年**，USPTO 就收到了**超过 65 万份专利申请**，其中包括对现有申请的复审请求【53】。

围绕专利驱动的创新，竞争环境和监管框架正在迅速变化。然而，尽管专利分析领域已经高度关注**文本数据**，但该领域仍**尚未被机器学习（ML）和自然语言处理（NLP）研究社区系统性地深入研究**。



![image-20250307101017436](pictures\image-20250307101017436.png)

这张图片展示了**Harvard USPTO Patent Dataset (HUPD)** 数据集中的**专利文档结构**，重点标出了不同的数据字段。下面是详细解析：

**图片内容**

**第一部分（左侧）**：

- 这是专利文档的首页，包含多个重要的元数据字段：
  - **Title（标题，绿色标注）**：专利的名称。
  - **Inventors（发明人，蓝色标注）**：发明专利的个人或公司。
  - **Application Number & File Date（申请号和提交日期）**：专利申请的唯一标识号和提交时间。
  - **IPC Classification（国际专利分类，绿色标注）**：专利所属的技术类别。
  - **CPC + USPC Classification（分类代码，绿色标注）**：CPC（合作专利分类）和 USPC（美国专利分类）。
  - **Publication Information（粉色标注）**：包括专利号、授权日期等信息。
  - **Examiner & Attorney（蓝色标注）**：审查员和代理律师的信息。
  - **Abstract（摘要，黄色标注）**：对专利的简要概述。

**第二部分（中间）**：

- 这是专利文档的**背景信息页**（Background，红色标注）。
- 描述了该专利的**技术背景**，包括现有技术的局限性，以及该发明如何改进现状。

**第三部分（右侧）**：

- 包含**详细描述（Detailed Description，蓝色标注）\**和\**摘要（Summary，绿色标注）**。
- 详细描述部分提供了专利的技术实现细节，例如技术方案、实施方式等。
- 摘要部分提供了专利的简要总结。



**缺乏大规模、结构良好且提炼过的专利数据是阻碍研究人员和实践者应用机器学习（ML）工具理解和探索技术创新及技术变革的主要障碍。近年来，尽管有一些尝试来解决这一限制，但到目前为止，所有用于自然语言处理（NLP）的专利数据集，包括 \*\*CLEF-IP 2011\*\* [38]、\*\*USPTO-2M\*\* [28] 和 \*\*BIGPATENT\*\* [46]，仍然在范围和功能上受到限制，如表 1 所示。这些数据集仅依赖于已授权专利的文本和信息，并且仅关注特定的专利授权时间点，包含的文本和字段受限，通常只专注于某个特定的 NLP 任务。我们在\**第 D 节**中对这些 NLP 数据集进行了更详细的讨论，同时介绍了其他流行的**原始专利文档**存储库和**非主要为 NLP 研究而设计的检索工具**。

因此，非常有必要拥有一个**免费、公开可用的数据集**，它能够提供更广泛和更全面的专利数据存储库——不仅涵盖**已授权专利**，还涵盖**专利申请**，同时包含多个部分和不同时期的数据。这种数据集提供了更大的灵活性和控制性，使其能够适用于多种实验和研究。基于这一目标，我们提出了**Harvard USPTO Patent Dataset (HUPD)**，这是第一个面向 NLP 研究社区的大规模、结构一致且多用途的专利文本语料库。该数据集包含**450 万份** 2004 年至 2018 年间提交至**美国专利商标局（USPTO）**的英语实用专利申请，旨在推动专利分析和 NLP 研究的发展。

**HUPD 与现有专利 NLP 数据集的三大关键区别**

**HUPD 专注于专利申请，而不仅仅是授权专利**

- 以往的专利数据集主要包含的是**已授权专利**，而 HUPD **收录了专利申请**，这些申请包含发明人提交的**原始权利要求和描述**。
- 这一特性允许我们在**申请时刻**获取一组一致的专利文档，避免了数据集在已授权和被拒绝专利不同修改阶段所带来的数据偏移问题。
- 访问**被接受和被拒绝专利的原始版本**，使我们能够引入一个全新的 NLP 任务——即**专利决策的二分类任务**（预测某项专利申请在提交时被接受的可能性）。

**HUPD 是第一个包含多个文本和结构化信息类别的 NLP 数据集**

- 现有专利 NLP 数据集通常**仅包含有限的专利字段**，例如**描述和摘要**。

- HUPD 具有

  34 个字段

  ，包括

  提交日期、细粒度分类代码、审查员信息

  等，这些丰富的信息能够支持更多 NLP 任务，例如：

  - 分析**专利语言和类别随时间的演变**，这些任务在过去的 NLP 专利数据集中无法实现。

**HUPD 直接使用**美国专利商标局（USPTO）**的数据，而非从 Google 的专利搜索（如 BIGPATENT）获取**

- 这样确保了数据的**完整性、全面性和结构化程度更高**，比以往的 NLP 专利数据集更大且更优质。



我们介绍了我们的专利数据集，并考虑到了多个目标群体。对于 **NLP 研究社区**，专利申请的庞大数据集——凭借其广泛的文本内容和结构化格式——提供了一个 **理想的领域特定实验室**，可用于开发和评估新的 NLP 工具。

------

**² 专利申请遵循严格且结构化的框架**：通常包含 **权利要求（claims）、描述（description）、附图（drawings）、背景信息（background）、摘要（abstract）和总结部分（summary）**。这些部分对于专利审查和文本分析至关重要。



**表 1：HUPD 与其他主要 NLP 专利分析数据集的比较**

下表比较了 HUPD 与其他专利 NLP 研究数据集。
**缩写解释**：

- **Abst**: 摘要（Abstract）
- **Appl**: 申请人信息（Applicant Information）
- **Exam**: 审查员信息（Examiner Information）
- **Invt**: 发明人信息（Inventor Information）
- **PD**: 公开日期（Publication Date）
- **Bkgd**: 背景信息（Background）
- **Dsc**: 详细描述（Description）
- **PCs**: IPC/CPC 分类代码（Patent Classification Codes）

![image-20250307103615901](pictures\image-20250307103615901.png)

我们的数据集 **HUPD** 在 **数据量**、**时间跨度** 和 **涵盖字段** 方面远超其他专利 NLP 数据集，同时具备 **多用途性**。

**主要优势**

- **HUPD 支持广泛的 NLP 任务**：从**专利文本摘要、信息检索** 到**命名实体识别（NER）和信息抽取（IE）**，涵盖多种任务。

- **研究专利的接受标准**：数据集的**结构化特性**使研究人员能够研究 **专利决策的接受标准如何随不同背景和时间变化**。

- 帮助 NLP 研究

  ：HUPD 支持各种专利分析任务，如：

  - **专利分类**（Patent Classification）
  - **技术领域的演变研究**
  - **先前技术搜索（Prior Art Search）**等。

此外，机器学习方法可以显著提高**专利检索、分类和预测的效率、价值和成本节约**。



专利申请通常包括标题、摘要、权利要求集、详细描述、附图（如果需要描述发明）以及与相关申请（如有）交叉引用的内容，以及其他书面规范。申请提交到美国专利商标局（USPTO）并由审查员进行审查，审查员通常需要具备与发明主题相关的专业知识和经验。

在审查过程中，审查员需要评估该发明的可专利性，决定该发明是否有用（useful）、非显而易见（non-obvious）且符合法定要求（statutory），同时检索该技术领域已有的相关技术，以确认所提交的权利要求是否具备新颖性（novel）。然后，审查员会向申请人发送官方通知，告知 USPTO 的决定。如果决定是有利的，那么申请人可以选择继续推进他们的申请，并由 USPTO 授予专利。如果决定是不利的，则申请人会收到拒绝通知，申请人可以选择是否对此进行回应、继续推进申请或请求复审。

在专利申请结果的预测任务中，我们需要明确什么是被接受和被拒绝的专利。我们认为专利申请在 USPTO 正式批准、授权并公开发布时，即被视为“接受”。然而，在专利审查过程中，并不存在明确的“绝对拒绝”概念。专利申请在初期通常会收到来自 USPTO 的官方通知，表明非最终拒绝或最终拒绝，通常是基于现有技术、权利要求范围、缺乏实用性或显而易见性等原因。但申请人可以向 USPTO 提交回应，并重新启动审查流程，即使在最终拒绝的情况下，申请仍然有可能在修改后被接受。因此，在我们的数据集中，如果一项专利申请收到了 USPTO 的正式拒绝通知（无论是非最终拒绝还是最终拒绝），并且最终未能获得授权，我们会将其标记为“拒绝”。

根据《专利审查程序手册（Manual of Patent Examining Procedure）》，如果申请人在规定时间内未对 USPTO 的拒绝通知采取行动或未作出回应，则该申请会被视为“放弃”。所有其他仍在 USPTO 处理中、尚未得到最终决定的专利申请都被归类为“待审”。

根据 Toole 等人的术语定义，我们将“专利申请”定义为尚未获得授权的发明申请，而“专利”仅指获得授权的专利。2001 年之前，USPTO 的专利申请不会公开，只有当专利被正式授权后才会披露。然而，根据 1999 年《美国发明人保护法案（American Inventors Protection Act）》，大多数专利申请会在最早申请日期后的 18 个月内公开，除非申请人要求提前公开。

USPTO 对于持续审查请求（RCEs）的提交次数没有限制，申请人可以提交多个请求来继续审查流程，但每次提交都会产生费用。



现有的用于自然语言处理（NLP）的专利数据集几乎专注于两个任务：专利主题分类和摘要生成。以下是这些领域中现有数据集和研究的概述。

自动主题分类

专利通常依据标准分类体系（如国际专利分类 IPC 和合作专利分类 CPC 系统）进行分类。这些 IPC/CPC 代码是分层的，分为类别级（如 G-物理学）、子类别级（如 G06F-电子数据处理）等。以往的研究尝试使用各种统计方法来预测专利的 IPC/CPC 代码，包括传统的统计学习工具（如经典统计学习方法）和神经网络架构（如 Transformer）。最近，研究人员开始使用 Transformer 模型进行这一任务。例如，Lee 和 Hsiang 通过微调预训练的 BERT 模型来预测 USPTO 专利的 IPC/CPC 代码。Zaheer 等人则在他们的 BigBird 模型上进行类似实验，并显示出比 BERT 更好的表现。

如表 1 所示，WIPO-alpha、CLEF-IP 和 USPTO-2M 主要用于自动 IPC/CPC 分类任务的模型训练，但这些数据集的范围仍然有限。它们包含的专利文本和元数据相对较少，无法让用户在训练和测试过程中自由选择关注的年份范围，并且有时在预处理和分词方面也较为困难。HUPD 解决了这些限制，提供了更多的数据选择灵活性，并包含更全面的文本字段和年份覆盖范围。

专利文本生成与摘要

近年来，随着大规模语言模型的兴起和成功，研究人员开始将 NLP 语言模型应用于专利领域。Sharma 等人最早进行了相关探索，提出了第一个专利摘要数据集 BigPatent，并使用该数据集训练摘要生成工具，以根据专利的描述部分生成其摘要。BigPatent 数据集包含 130 万件 1971 年至 2018 年间提交到 USPTO 的实用专利，并是从 Google Patents Public Dataset via BigQuery 中收集的。

HUPD 数据集与 BigPatent 数据集的不同之处有三点：

1. HUPD 包含的元数据和字段更多，包括权利要求、背景信息、申请日期和审查员信息，而这些内容在 BigPatent 中并不存在；
2. 除了已被接受的专利外，HUPD 还包含被拒绝和待决的专利申请，使其能够研究专利接受/拒绝的模式；
3. HUPD 包含的文档数量约为 BigPatent 的三倍（见表 1）。

**专利接受预测**

据我们所知，本研究是第一个在专利审查过程中引入专利拒绝预测的实际定义，并分析和讨论被接受与被拒绝专利申请之间的特征模式的研究，且仅从**文本**角度出发进行分析。因此，我们将专利决策分类任务引入 NLP 研究领域。

哈佛 USPTO 专利数据集（HUPD）包含 4,518,263 份 2004 年 1 月至 2018 年 12 月间提交至 USPTO 的实用专利申请[²]。在本节中，我们详细介绍数据收集过程，并提供数据格式和数据集结构的相关信息。此外，我们枚举并突出数据的统计属性，承认数据集的局限性，并讨论本研究的伦理考虑。更多信息见**第 B 节**。

数据集构建

根据美国法律，所有专利数据均为**公开可访问**的。然而，获取专利数据及其相关元数据的过程涉及多个步骤，包括：标准化所有数据格式、筛除缺失或错误数据、去重、合并，并将所有数据整合为一个易于使用的数据集。这一过程并不简单，以下是该过程的概述。

专利申请文本是从**USPTO 批量数据存储系统（BDSS）\**获取的（\*\*专利申请数据/XML 版本\*\*），以 XML 文件格式存储[¹³]。由于并非所有原始专利文件都遵循相同的 XML 结构，我们编写了正则表达式来解析不同格式，将其标准化，并存储为结构化 JSON 文件。与申请相关的元数据（包括接受/拒绝决定、申请日期、标题和分类信息）则是从\**USPTO 专利审查研究数据集**中单独下载的[¹⁷, ³⁴]（2021 年 2 月）。这些元数据随后与 BDSS 提供的完整专利文本进行合并，以关联 2020 年之前的专利文档，包括审查员信息、专利局决定、额外的申请信息等。通过这一合并过程，我们的数据集既包含更新的元数据结构，又涵盖了专利文本内容。

最后，我们整合了每个专利申请的**续案申请（continuation application）\**信息：凡是在\**USPTO 申请连续性数据文件**中与父申请相关联的专利，均在**决策状态字段**中加上前缀“CONT-”[¹⁴]。因此，最终的专利决策状态字段包含 6 种标签：“Accepted”（已接受）、“Rejected”（已拒绝）、“Pending”（待审）、“CONT-Accepted”（续案-已接受）、“CONT-Rejected”（续案-已拒绝）和“CONT-Pending”（续案-待审）[¹⁵]。

统计信息

表 1 提供了 HUPD 数据集与其他专利数据源的**数量对比**，表 2 则提供了基于文本的专利信息和统计数据。HUPD 在现有专利数据集（如 BigPatent）的基础上进行了扩展，不仅提高了数据规模，还增加了覆盖范围，使用户能够观察专利家族（patent families）的演变情况。此外，图 10（见**第 G 节**）展示了 2011-2016 年间 6 类决策状态标签的具体分布情况。

数据集局限性

- **方法论局限**：数据集仅包含**美国专利局（USPTO）\**的专利，且所有专利数据均为\**英文**，不包含图像内容（如专利附图）。
- **功能局限**：某些专利文本部分较长，可能超过现有 NLP 模型的处理能力。此外，专利文本中包含的**专业术语和分类词汇**可能会影响当前 NLP 词向量模型的表现。

潜在偏差

我们在**第 C 节**分析了 HUPD 数据集的潜在偏差，并建议研究人员在使用 HUPD 进行实验时考虑这些偏差，特别是在涉及**发明人信息**和**审查员信息**的分析时。

伦理考量

在构建 HUPD 数据集时，我们参考了 Gebru 等人[¹³] 和 Bender & Friedman[³] 提出的**数据表单**和伦理标准，并探讨了动机、目标等相关因素。



由于 HUPD 的多功能性，可以从数据集中选择适当的字段和元数据构建各种 NLP 任务和实验。在本节中，我们重点介绍四个我们认为对 NLP 和知识产权（IP）社区最有价值和相关的任务：（i）专利决策的二元分类，（ii）专利 IPC/CPC 类别的多标签分类，（iii）语言建模，以及（iv）摘要任务。当然，该数据集也可以用于其他研究，例如专利聚类、先前技术检索以及超级发明家的早期检测等研究[¹⁷]。在接下来的内容中，我们详细描述这四个任务，并探讨它们在知识产权领域的重要性。**表 3** 提供了每个任务的概述以及用于衡量任务性能的相应指标。

**专利接受预测（Patent Acceptance Prediction）**

给定专利申请的某个部分（特别是摘要、权利要求或描述），我们预测该申请是否会被 USPTO 接受。从 NLP 社区的角度来看，这是一个标准的分类任务。然而，该决策任务的潜在应用和好处，以及其难度，使其有别于常见的二元分类基准任务（如 SST、Yelp）。在我们的实验中，我们专注于**不包含父申请**的专利申请，以保持样本的简单性和清晰性，因此排除了所有 CONT-申请。此外，我们不包含任何待审申请（Pending Applications）。

**自动主题分类（Automated Subject Classification）**

下一个任务是**预测专利文本的主要 IPC 或 CPC 代码**（基于部分或全部文本）。对专利文件进行一致的自动分类，使其归属于不同的技术领域，可以帮助专利审查员更有效地分配专利申请。此外，该任务有助于创建严格且标准化的**先前技术目录**，以支持研究和探索。该任务还可能有助于早期识别跨多个技术领域的**高价值发明**，或新兴的技术领域。

在我们的实验设置中，我们预测专利申请的**子类级别**的 IPC 代码，因为 IPC 代码适用于更大范围的专利，而 CPC 代码的适用范围较小[¹⁸]。在我们的数据集中，共有 637 个子类级别的 IPC 代码，但它们的分布**并不均匀**（见**图 2**）；例如，**G06F - 电子数据处理（Electric Digital Data Processing）** 占 2011-2016 年间被接受专利的 **10.4%**，而最流行的 **15 个 IPC 代码** 占比接近 **40%**。因此，仅预测主要类别很难获得良好的分类性能。

**语言建模（Language Modeling）**

我们从分类任务转向**语言建模（LM）**。我们首先考虑专利权利要求（claims）部分的**掩码语言模型（masked LM）**。我们重点关注权利要求部分，因为它构成了专利申请中所描述发明的基础，具有**独特的语言风格**，并且被认为是专利中**法律效力最强的部分**。此外，我们还对**专利摘要部分**进行语言建模实验，该部分的语言与标准自然语言更为相似。这些语言模型可用于**下游任务**，以及**特定领域的研究**。

在 **第 1 节**[¹⁹] 中，我们展示了一种简单但有趣的 LMs 应用，即通过可视化不同专利类别在该**微调语言模型**下的平均嵌入，捕捉**专利申请中创新概念和趋势的文本演变**，并分析它们在不同技术领域的分布。

**抽象摘要生成（Abstractive Summarization）**

最终任务的设定**自然而然地**源自专利数据的结构：**每个专利都包含一个摘要（abstract），申请人在其中概述了专利的内容**。在我们的**抽象摘要任务**中，我们使用该部分作为**摘要生成的真实标签（ground truth）**，而**权利要求（claims）或描述（description）**则作为源文本（source text）。

我们进行的这种**条件生成任务（conditional generation task）**，与 Sharma 等人[⁴⁶] 的研究**具有相同的动机**，但我们的数据集在规模和范围上有所不同。与 Sharma 等人[⁴⁶] 的方法相比，我们的实验设置**更进一步**，允许使用**权利要求（claims）或描述（description）** 作为源文本，而 Sharma 等人[⁴⁶] 仅使用了**描述（description）部分**[²⁰]。

# 决策二分类任务代码

```python3
input = np.array([
    [1, 3, 3, 5],
    [0, 2, 2, 9, 9]  # 注意：实际情况中各样本长度可能不一致，但这里为了演示我们假设已经做了 padding
]) # input.shape[0]表示第一维度的大小也就是2,input[0].shape[0]表示第一行数据第一维度的大小也就是4，对于一维numpy数组shpae[0]表示数组中数据的个数
```

```python3
def text2bow(input, vocab_size):
	arr = []
	for i in range(input.shape[0]):
		query = input[i]
		features = [0] * vocab_size
		for j in range(query.shape[0]):
			features[query[j]] += 1
		arr.append(features)
	return arr
# 对每一个输入形成一个词袋
```

